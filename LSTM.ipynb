{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data=[[[(i+j)] for i in range(5)] for j in range(100)]                  \n",
    "target=[(i+5) for i in range(100)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=np.array(Data,dtype=float)\n",
    "target=np.array(target,dtype=float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 5, 1)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data/=100\n",
    "target/=100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test=train_test_split(data,target,test_size=0.2, random_state=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.04],\n",
       "       [0.05],\n",
       "       [0.06],\n",
       "       [0.07],\n",
       "       [0.08]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\lenovo\\AppData\\Local\\conda\\conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "model=Sequential()\n",
    "model.add(LSTM((1),batch_input_shape=(None,5,1),return_sequences=True))\n",
    "model.add(LSTM((1),return_sequences=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model.compile(loss='mean_absolute_error',optimizer='adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 5, 1)              12        \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 1)                 12        \n",
      "=================================================================\n",
      "Total params: 24\n",
      "Trainable params: 24\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\lenovo\\AppData\\Local\\conda\\conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 80 samples, validate on 20 samples\n",
      "Epoch 1/300\n",
      "80/80 [==============================] - 2s 24ms/step - loss: 0.5848 - acc: 0.0000e+00 - val_loss: 0.4713 - val_acc: 0.0000e+00\n",
      "Epoch 2/300\n",
      "80/80 [==============================] - 0s 301us/step - loss: 0.5827 - acc: 0.0000e+00 - val_loss: 0.4693 - val_acc: 0.0000e+00\n",
      "Epoch 3/300\n",
      "80/80 [==============================] - 0s 295us/step - loss: 0.5807 - acc: 0.0000e+00 - val_loss: 0.4673 - val_acc: 0.0000e+00\n",
      "Epoch 4/300\n",
      "80/80 [==============================] - 0s 274us/step - loss: 0.5787 - acc: 0.0000e+00 - val_loss: 0.4654 - val_acc: 0.0000e+00\n",
      "Epoch 5/300\n",
      "80/80 [==============================] - 0s 295us/step - loss: 0.5767 - acc: 0.0000e+00 - val_loss: 0.4634 - val_acc: 0.0000e+00\n",
      "Epoch 6/300\n",
      "80/80 [==============================] - 0s 274us/step - loss: 0.5747 - acc: 0.0000e+00 - val_loss: 0.4615 - val_acc: 0.0000e+00\n",
      "Epoch 7/300\n",
      "80/80 [==============================] - 0s 287us/step - loss: 0.5728 - acc: 0.0000e+00 - val_loss: 0.4596 - val_acc: 0.0000e+00\n",
      "Epoch 8/300\n",
      "80/80 [==============================] - 0s 299us/step - loss: 0.5709 - acc: 0.0000e+00 - val_loss: 0.4578 - val_acc: 0.0000e+00\n",
      "Epoch 9/300\n",
      "80/80 [==============================] - 0s 312us/step - loss: 0.5690 - acc: 0.0000e+00 - val_loss: 0.4560 - val_acc: 0.0000e+00\n",
      "Epoch 10/300\n",
      "80/80 [==============================] - 0s 324us/step - loss: 0.5672 - acc: 0.0000e+00 - val_loss: 0.4541 - val_acc: 0.0000e+00\n",
      "Epoch 11/300\n",
      "80/80 [==============================] - 0s 299us/step - loss: 0.5653 - acc: 0.0000e+00 - val_loss: 0.4523 - val_acc: 0.0000e+00\n",
      "Epoch 12/300\n",
      "80/80 [==============================] - 0s 337us/step - loss: 0.5635 - acc: 0.0000e+00 - val_loss: 0.4505 - val_acc: 0.0000e+00\n",
      "Epoch 13/300\n",
      "80/80 [==============================] - 0s 312us/step - loss: 0.5617 - acc: 0.0000e+00 - val_loss: 0.4487 - val_acc: 0.0000e+00\n",
      "Epoch 14/300\n",
      "80/80 [==============================] - 0s 312us/step - loss: 0.5599 - acc: 0.0000e+00 - val_loss: 0.4469 - val_acc: 0.0000e+00\n",
      "Epoch 15/300\n",
      "80/80 [==============================] - 0s 287us/step - loss: 0.5580 - acc: 0.0000e+00 - val_loss: 0.4451 - val_acc: 0.0000e+00\n",
      "Epoch 16/300\n",
      "80/80 [==============================] - 0s 312us/step - loss: 0.5562 - acc: 0.0000e+00 - val_loss: 0.4433 - val_acc: 0.0000e+00\n",
      "Epoch 17/300\n",
      "80/80 [==============================] - 0s 287us/step - loss: 0.5544 - acc: 0.0000e+00 - val_loss: 0.4414 - val_acc: 0.0000e+00\n",
      "Epoch 18/300\n",
      "80/80 [==============================] - 0s 299us/step - loss: 0.5525 - acc: 0.0000e+00 - val_loss: 0.4395 - val_acc: 0.0000e+00\n",
      "Epoch 19/300\n",
      "80/80 [==============================] - 0s 324us/step - loss: 0.5506 - acc: 0.0000e+00 - val_loss: 0.4377 - val_acc: 0.0000e+00\n",
      "Epoch 20/300\n",
      "80/80 [==============================] - 0s 287us/step - loss: 0.5487 - acc: 0.0000e+00 - val_loss: 0.4357 - val_acc: 0.0000e+00\n",
      "Epoch 21/300\n",
      "80/80 [==============================] - 0s 324us/step - loss: 0.5468 - acc: 0.0000e+00 - val_loss: 0.4338 - val_acc: 0.0000e+00\n",
      "Epoch 22/300\n",
      "80/80 [==============================] - 0s 274us/step - loss: 0.5449 - acc: 0.0000e+00 - val_loss: 0.4318 - val_acc: 0.0000e+00\n",
      "Epoch 23/300\n",
      "80/80 [==============================] - 0s 312us/step - loss: 0.5429 - acc: 0.0000e+00 - val_loss: 0.4298 - val_acc: 0.0000e+00\n",
      "Epoch 24/300\n",
      "80/80 [==============================] - 0s 324us/step - loss: 0.5409 - acc: 0.0000e+00 - val_loss: 0.4278 - val_acc: 0.0000e+00\n",
      "Epoch 25/300\n",
      "80/80 [==============================] - 0s 324us/step - loss: 0.5388 - acc: 0.0000e+00 - val_loss: 0.4257 - val_acc: 0.0000e+00\n",
      "Epoch 26/300\n",
      "80/80 [==============================] - 0s 324us/step - loss: 0.5368 - acc: 0.0000e+00 - val_loss: 0.4236 - val_acc: 0.0000e+00\n",
      "Epoch 27/300\n",
      "80/80 [==============================] - 0s 299us/step - loss: 0.5347 - acc: 0.0000e+00 - val_loss: 0.4215 - val_acc: 0.0000e+00\n",
      "Epoch 28/300\n",
      "80/80 [==============================] - 0s 337us/step - loss: 0.5325 - acc: 0.0000e+00 - val_loss: 0.4194 - val_acc: 0.0000e+00\n",
      "Epoch 29/300\n",
      "80/80 [==============================] - 0s 312us/step - loss: 0.5304 - acc: 0.0000e+00 - val_loss: 0.4172 - val_acc: 0.0000e+00\n",
      "Epoch 30/300\n",
      "80/80 [==============================] - 0s 299us/step - loss: 0.5282 - acc: 0.0000e+00 - val_loss: 0.4150 - val_acc: 0.0000e+00\n",
      "Epoch 31/300\n",
      "80/80 [==============================] - 0s 299us/step - loss: 0.5261 - acc: 0.0000e+00 - val_loss: 0.4127 - val_acc: 0.0000e+00\n",
      "Epoch 32/300\n",
      "80/80 [==============================] - 0s 324us/step - loss: 0.5239 - acc: 0.0000e+00 - val_loss: 0.4105 - val_acc: 0.0000e+00\n",
      "Epoch 33/300\n",
      "80/80 [==============================] - 0s 299us/step - loss: 0.5216 - acc: 0.0000e+00 - val_loss: 0.4082 - val_acc: 0.0000e+00\n",
      "Epoch 34/300\n",
      "80/80 [==============================] - 0s 299us/step - loss: 0.5194 - acc: 0.0000e+00 - val_loss: 0.4058 - val_acc: 0.0000e+00\n",
      "Epoch 35/300\n",
      "80/80 [==============================] - 0s 299us/step - loss: 0.5172 - acc: 0.0000e+00 - val_loss: 0.4035 - val_acc: 0.0000e+00\n",
      "Epoch 36/300\n",
      "80/80 [==============================] - 0s 312us/step - loss: 0.5150 - acc: 0.0000e+00 - val_loss: 0.4011 - val_acc: 0.0000e+00\n",
      "Epoch 37/300\n",
      "80/80 [==============================] - 0s 324us/step - loss: 0.5127 - acc: 0.0000e+00 - val_loss: 0.3987 - val_acc: 0.0000e+00\n",
      "Epoch 38/300\n",
      "80/80 [==============================] - 0s 312us/step - loss: 0.5104 - acc: 0.0000e+00 - val_loss: 0.3965 - val_acc: 0.0000e+00\n",
      "Epoch 39/300\n",
      "80/80 [==============================] - 0s 349us/step - loss: 0.5081 - acc: 0.0000e+00 - val_loss: 0.3943 - val_acc: 0.0000e+00\n",
      "Epoch 40/300\n",
      "80/80 [==============================] - 0s 312us/step - loss: 0.5058 - acc: 0.0000e+00 - val_loss: 0.3920 - val_acc: 0.0000e+00\n",
      "Epoch 41/300\n",
      "80/80 [==============================] - 0s 337us/step - loss: 0.5034 - acc: 0.0000e+00 - val_loss: 0.3897 - val_acc: 0.0000e+00\n",
      "Epoch 42/300\n",
      "80/80 [==============================] - 0s 337us/step - loss: 0.5010 - acc: 0.0000e+00 - val_loss: 0.3874 - val_acc: 0.0000e+00\n",
      "Epoch 43/300\n",
      "80/80 [==============================] - 0s 287us/step - loss: 0.4985 - acc: 0.0000e+00 - val_loss: 0.3850 - val_acc: 0.0000e+00\n",
      "Epoch 44/300\n",
      "80/80 [==============================] - 0s 312us/step - loss: 0.4961 - acc: 0.0000e+00 - val_loss: 0.3827 - val_acc: 0.0000e+00\n",
      "Epoch 45/300\n",
      "80/80 [==============================] - 0s 299us/step - loss: 0.4937 - acc: 0.0000e+00 - val_loss: 0.3802 - val_acc: 0.0000e+00\n",
      "Epoch 46/300\n",
      "80/80 [==============================] - 0s 287us/step - loss: 0.4912 - acc: 0.0000e+00 - val_loss: 0.3778 - val_acc: 0.0000e+00\n",
      "Epoch 47/300\n",
      "80/80 [==============================] - 0s 299us/step - loss: 0.4886 - acc: 0.0000e+00 - val_loss: 0.3753 - val_acc: 0.0000e+00\n",
      "Epoch 48/300\n",
      "80/80 [==============================] - 0s 287us/step - loss: 0.4861 - acc: 0.0000e+00 - val_loss: 0.3727 - val_acc: 0.0000e+00\n",
      "Epoch 49/300\n",
      "80/80 [==============================] - 0s 287us/step - loss: 0.4837 - acc: 0.0000e+00 - val_loss: 0.3702 - val_acc: 0.0000e+00\n",
      "Epoch 50/300\n",
      "80/80 [==============================] - 0s 299us/step - loss: 0.4811 - acc: 0.0000e+00 - val_loss: 0.3676 - val_acc: 0.0000e+00\n",
      "Epoch 51/300\n",
      "80/80 [==============================] - 0s 287us/step - loss: 0.4786 - acc: 0.0000e+00 - val_loss: 0.3650 - val_acc: 0.0000e+00\n",
      "Epoch 52/300\n",
      "80/80 [==============================] - 0s 299us/step - loss: 0.4760 - acc: 0.0000e+00 - val_loss: 0.3623 - val_acc: 0.0000e+00\n",
      "Epoch 53/300\n",
      "80/80 [==============================] - 0s 287us/step - loss: 0.4735 - acc: 0.0000e+00 - val_loss: 0.3597 - val_acc: 0.0000e+00\n",
      "Epoch 54/300\n",
      "80/80 [==============================] - 0s 287us/step - loss: 0.4709 - acc: 0.0000e+00 - val_loss: 0.3570 - val_acc: 0.0000e+00\n",
      "Epoch 55/300\n",
      "80/80 [==============================] - 0s 287us/step - loss: 0.4683 - acc: 0.0000e+00 - val_loss: 0.3543 - val_acc: 0.0000e+00\n",
      "Epoch 56/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80/80 [==============================] - 0s 274us/step - loss: 0.4659 - acc: 0.0000e+00 - val_loss: 0.3515 - val_acc: 0.0000e+00\n",
      "Epoch 57/300\n",
      "80/80 [==============================] - 0s 312us/step - loss: 0.4632 - acc: 0.0000e+00 - val_loss: 0.3487 - val_acc: 0.0000e+00\n",
      "Epoch 58/300\n",
      "80/80 [==============================] - 0s 411us/step - loss: 0.4607 - acc: 0.0000e+00 - val_loss: 0.3459 - val_acc: 0.0000e+00\n",
      "Epoch 59/300\n",
      "80/80 [==============================] - 0s 362us/step - loss: 0.4580 - acc: 0.0000e+00 - val_loss: 0.3430 - val_acc: 0.0000e+00\n",
      "Epoch 60/300\n",
      "80/80 [==============================] - 0s 324us/step - loss: 0.4555 - acc: 0.0000e+00 - val_loss: 0.3401 - val_acc: 0.0000e+00\n",
      "Epoch 61/300\n",
      "80/80 [==============================] - 0s 299us/step - loss: 0.4528 - acc: 0.0000e+00 - val_loss: 0.3373 - val_acc: 0.0000e+00\n",
      "Epoch 62/300\n",
      "80/80 [==============================] - 0s 287us/step - loss: 0.4503 - acc: 0.0000e+00 - val_loss: 0.3343 - val_acc: 0.0000e+00\n",
      "Epoch 63/300\n",
      "80/80 [==============================] - 0s 312us/step - loss: 0.4476 - acc: 0.0000e+00 - val_loss: 0.3313 - val_acc: 0.0000e+00\n",
      "Epoch 64/300\n",
      "80/80 [==============================] - 0s 424us/step - loss: 0.4451 - acc: 0.0000e+00 - val_loss: 0.3283 - val_acc: 0.0000e+00\n",
      "Epoch 65/300\n",
      "80/80 [==============================] - 0s 411us/step - loss: 0.4424 - acc: 0.0000e+00 - val_loss: 0.3253 - val_acc: 0.0000e+00\n",
      "Epoch 66/300\n",
      "80/80 [==============================] - 0s 436us/step - loss: 0.4398 - acc: 0.0000e+00 - val_loss: 0.3224 - val_acc: 0.0000e+00\n",
      "Epoch 67/300\n",
      "80/80 [==============================] - 0s 399us/step - loss: 0.4372 - acc: 0.0000e+00 - val_loss: 0.3197 - val_acc: 0.0000e+00\n",
      "Epoch 68/300\n",
      "80/80 [==============================] - 0s 337us/step - loss: 0.4346 - acc: 0.0000e+00 - val_loss: 0.3169 - val_acc: 0.0000e+00\n",
      "Epoch 69/300\n",
      "80/80 [==============================] - 0s 274us/step - loss: 0.4319 - acc: 0.0000e+00 - val_loss: 0.3140 - val_acc: 0.0000e+00\n",
      "Epoch 70/300\n",
      "80/80 [==============================] - 0s 287us/step - loss: 0.4292 - acc: 0.0000e+00 - val_loss: 0.3112 - val_acc: 0.0000e+00\n",
      "Epoch 71/300\n",
      "80/80 [==============================] - 0s 274us/step - loss: 0.4264 - acc: 0.0000e+00 - val_loss: 0.3083 - val_acc: 0.0000e+00\n",
      "Epoch 72/300\n",
      "80/80 [==============================] - 0s 349us/step - loss: 0.4238 - acc: 0.0000e+00 - val_loss: 0.3054 - val_acc: 0.0000e+00\n",
      "Epoch 73/300\n",
      "80/80 [==============================] - 0s 349us/step - loss: 0.4210 - acc: 0.0000e+00 - val_loss: 0.3024 - val_acc: 0.0000e+00\n",
      "Epoch 74/300\n",
      "80/80 [==============================] - 0s 312us/step - loss: 0.4183 - acc: 0.0000e+00 - val_loss: 0.2995 - val_acc: 0.0000e+00\n",
      "Epoch 75/300\n",
      "80/80 [==============================] - 0s 349us/step - loss: 0.4157 - acc: 0.0000e+00 - val_loss: 0.2967 - val_acc: 0.0000e+00\n",
      "Epoch 76/300\n",
      "80/80 [==============================] - 0s 337us/step - loss: 0.4130 - acc: 0.0000e+00 - val_loss: 0.2939 - val_acc: 0.0000e+00\n",
      "Epoch 77/300\n",
      "80/80 [==============================] - 0s 337us/step - loss: 0.4100 - acc: 0.0000e+00 - val_loss: 0.2912 - val_acc: 0.0000e+00\n",
      "Epoch 78/300\n",
      "80/80 [==============================] - 0s 424us/step - loss: 0.4073 - acc: 0.0000e+00 - val_loss: 0.2888 - val_acc: 0.0000e+00\n",
      "Epoch 79/300\n",
      "80/80 [==============================] - 0s 361us/step - loss: 0.4044 - acc: 0.0000e+00 - val_loss: 0.2864 - val_acc: 0.0000e+00\n",
      "Epoch 80/300\n",
      "80/80 [==============================] - 0s 486us/step - loss: 0.4014 - acc: 0.0000e+00 - val_loss: 0.2839 - val_acc: 0.0000e+00\n",
      "Epoch 81/300\n",
      "80/80 [==============================] - 0s 436us/step - loss: 0.3986 - acc: 0.0000e+00 - val_loss: 0.2814 - val_acc: 0.0000e+00\n",
      "Epoch 82/300\n",
      "80/80 [==============================] - 0s 349us/step - loss: 0.3957 - acc: 0.0000e+00 - val_loss: 0.2789 - val_acc: 0.0000e+00\n",
      "Epoch 83/300\n",
      "80/80 [==============================] - 0s 461us/step - loss: 0.3925 - acc: 0.0000e+00 - val_loss: 0.2768 - val_acc: 0.0000e+00\n",
      "Epoch 84/300\n",
      "80/80 [==============================] - 0s 524us/step - loss: 0.3897 - acc: 0.0000e+00 - val_loss: 0.2747 - val_acc: 0.0000e+00\n",
      "Epoch 85/300\n",
      "80/80 [==============================] - 0s 474us/step - loss: 0.3867 - acc: 0.0000e+00 - val_loss: 0.2724 - val_acc: 0.0000e+00\n",
      "Epoch 86/300\n",
      "80/80 [==============================] - 0s 524us/step - loss: 0.3836 - acc: 0.0000e+00 - val_loss: 0.2702 - val_acc: 0.0000e+00\n",
      "Epoch 87/300\n",
      "80/80 [==============================] - 0s 561us/step - loss: 0.3806 - acc: 0.0000e+00 - val_loss: 0.2680 - val_acc: 0.0000e+00\n",
      "Epoch 88/300\n",
      "80/80 [==============================] - 0s 486us/step - loss: 0.3778 - acc: 0.0000e+00 - val_loss: 0.2657 - val_acc: 0.0000e+00\n",
      "Epoch 89/300\n",
      "80/80 [==============================] - 0s 524us/step - loss: 0.3748 - acc: 0.0000e+00 - val_loss: 0.2635 - val_acc: 0.0000e+00\n",
      "Epoch 90/300\n",
      "80/80 [==============================] - 0s 499us/step - loss: 0.3722 - acc: 0.0000e+00 - val_loss: 0.2613 - val_acc: 0.0000e+00\n",
      "Epoch 91/300\n",
      "80/80 [==============================] - 0s 411us/step - loss: 0.3692 - acc: 0.0000e+00 - val_loss: 0.2591 - val_acc: 0.0000e+00\n",
      "Epoch 92/300\n",
      "80/80 [==============================] - 0s 461us/step - loss: 0.3665 - acc: 0.0000e+00 - val_loss: 0.2572 - val_acc: 0.0000e+00\n",
      "Epoch 93/300\n",
      "80/80 [==============================] - 0s 374us/step - loss: 0.3637 - acc: 0.0000e+00 - val_loss: 0.2555 - val_acc: 0.0000e+00\n",
      "Epoch 94/300\n",
      "80/80 [==============================] - 0s 312us/step - loss: 0.3609 - acc: 0.0000e+00 - val_loss: 0.2537 - val_acc: 0.0000e+00\n",
      "Epoch 95/300\n",
      "80/80 [==============================] - 0s 299us/step - loss: 0.3582 - acc: 0.0000e+00 - val_loss: 0.2518 - val_acc: 0.0000e+00\n",
      "Epoch 96/300\n",
      "80/80 [==============================] - 0s 324us/step - loss: 0.3554 - acc: 0.0000e+00 - val_loss: 0.2500 - val_acc: 0.0000e+00\n",
      "Epoch 97/300\n",
      "80/80 [==============================] - 0s 299us/step - loss: 0.3528 - acc: 0.0000e+00 - val_loss: 0.2481 - val_acc: 0.0000e+00\n",
      "Epoch 98/300\n",
      "80/80 [==============================] - 0s 299us/step - loss: 0.3500 - acc: 0.0000e+00 - val_loss: 0.2462 - val_acc: 0.0000e+00\n",
      "Epoch 99/300\n",
      "80/80 [==============================] - 0s 274us/step - loss: 0.3474 - acc: 0.0000e+00 - val_loss: 0.2443 - val_acc: 0.0000e+00\n",
      "Epoch 100/300\n",
      "80/80 [==============================] - 0s 287us/step - loss: 0.3449 - acc: 0.0000e+00 - val_loss: 0.2425 - val_acc: 0.0000e+00\n",
      "Epoch 101/300\n",
      "80/80 [==============================] - 0s 287us/step - loss: 0.3423 - acc: 0.0000e+00 - val_loss: 0.2410 - val_acc: 0.0000e+00\n",
      "Epoch 102/300\n",
      "80/80 [==============================] - 0s 274us/step - loss: 0.3396 - acc: 0.0000e+00 - val_loss: 0.2397 - val_acc: 0.0000e+00\n",
      "Epoch 103/300\n",
      "80/80 [==============================] - 0s 312us/step - loss: 0.3373 - acc: 0.0000e+00 - val_loss: 0.2383 - val_acc: 0.0000e+00\n",
      "Epoch 104/300\n",
      "80/80 [==============================] - 0s 299us/step - loss: 0.3348 - acc: 0.0000e+00 - val_loss: 0.2369 - val_acc: 0.0000e+00\n",
      "Epoch 105/300\n",
      "80/80 [==============================] - 0s 337us/step - loss: 0.3322 - acc: 0.0000e+00 - val_loss: 0.2357 - val_acc: 0.0000e+00\n",
      "Epoch 106/300\n",
      "80/80 [==============================] - 0s 324us/step - loss: 0.3297 - acc: 0.0000e+00 - val_loss: 0.2348 - val_acc: 0.0000e+00\n",
      "Epoch 107/300\n",
      "80/80 [==============================] - 0s 312us/step - loss: 0.3274 - acc: 0.0000e+00 - val_loss: 0.2338 - val_acc: 0.0000e+00\n",
      "Epoch 108/300\n",
      "80/80 [==============================] - 0s 287us/step - loss: 0.3250 - acc: 0.0000e+00 - val_loss: 0.2329 - val_acc: 0.0000e+00\n",
      "Epoch 109/300\n",
      "80/80 [==============================] - 0s 374us/step - loss: 0.3222 - acc: 0.0000e+00 - val_loss: 0.2319 - val_acc: 0.0000e+00\n",
      "Epoch 110/300\n",
      "80/80 [==============================] - 0s 461us/step - loss: 0.3201 - acc: 0.0000e+00 - val_loss: 0.2309 - val_acc: 0.0000e+00\n",
      "Epoch 111/300\n",
      "80/80 [==============================] - 0s 461us/step - loss: 0.3177 - acc: 0.0000e+00 - val_loss: 0.2300 - val_acc: 0.0000e+00\n",
      "Epoch 112/300\n",
      "80/80 [==============================] - 0s 636us/step - loss: 0.3153 - acc: 0.0000e+00 - val_loss: 0.2295 - val_acc: 0.0000e+00\n",
      "Epoch 113/300\n",
      "80/80 [==============================] - 0s 362us/step - loss: 0.3130 - acc: 0.0000e+00 - val_loss: 0.2290 - val_acc: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 114/300\n",
      "80/80 [==============================] - 0s 436us/step - loss: 0.3109 - acc: 0.0000e+00 - val_loss: 0.2286 - val_acc: 0.0000e+00\n",
      "Epoch 115/300\n",
      "80/80 [==============================] - 0s 549us/step - loss: 0.3088 - acc: 0.0000e+00 - val_loss: 0.2281 - val_acc: 0.0000e+00\n",
      "Epoch 116/300\n",
      "80/80 [==============================] - 0s 636us/step - loss: 0.3066 - acc: 0.0000e+00 - val_loss: 0.2276 - val_acc: 0.0000e+00\n",
      "Epoch 117/300\n",
      "80/80 [==============================] - 0s 524us/step - loss: 0.3046 - acc: 0.0000e+00 - val_loss: 0.2272 - val_acc: 0.0000e+00\n",
      "Epoch 118/300\n",
      "80/80 [==============================] - 0s 399us/step - loss: 0.3026 - acc: 0.0000e+00 - val_loss: 0.2267 - val_acc: 0.0000e+00\n",
      "Epoch 119/300\n",
      "80/80 [==============================] - 0s 499us/step - loss: 0.3007 - acc: 0.0000e+00 - val_loss: 0.2262 - val_acc: 0.0000e+00\n",
      "Epoch 120/300\n",
      "80/80 [==============================] - 0s 549us/step - loss: 0.2990 - acc: 0.0000e+00 - val_loss: 0.2257 - val_acc: 0.0000e+00\n",
      "Epoch 121/300\n",
      "80/80 [==============================] - 0s 312us/step - loss: 0.2971 - acc: 0.0000e+00 - val_loss: 0.2253 - val_acc: 0.0000e+00\n",
      "Epoch 122/300\n",
      "80/80 [==============================] - 0s 312us/step - loss: 0.2954 - acc: 0.0000e+00 - val_loss: 0.2248 - val_acc: 0.0000e+00\n",
      "Epoch 123/300\n",
      "80/80 [==============================] - 0s 324us/step - loss: 0.2937 - acc: 0.0000e+00 - val_loss: 0.2244 - val_acc: 0.0000e+00\n",
      "Epoch 124/300\n",
      "80/80 [==============================] - 0s 374us/step - loss: 0.2925 - acc: 0.0000e+00 - val_loss: 0.2239 - val_acc: 0.0000e+00\n",
      "Epoch 125/300\n",
      "80/80 [==============================] - 0s 411us/step - loss: 0.2908 - acc: 0.0000e+00 - val_loss: 0.2237 - val_acc: 0.0000e+00\n",
      "Epoch 126/300\n",
      "80/80 [==============================] - 0s 486us/step - loss: 0.2893 - acc: 0.0000e+00 - val_loss: 0.2237 - val_acc: 0.0000e+00\n",
      "Epoch 127/300\n",
      "80/80 [==============================] - 0s 424us/step - loss: 0.2880 - acc: 0.0000e+00 - val_loss: 0.2237 - val_acc: 0.0000e+00\n",
      "Epoch 128/300\n",
      "80/80 [==============================] - 0s 486us/step - loss: 0.2865 - acc: 0.0000e+00 - val_loss: 0.2236 - val_acc: 0.0000e+00\n",
      "Epoch 129/300\n",
      "80/80 [==============================] - 0s 499us/step - loss: 0.2854 - acc: 0.0000e+00 - val_loss: 0.2236 - val_acc: 0.0000e+00\n",
      "Epoch 130/300\n",
      "80/80 [==============================] - 0s 374us/step - loss: 0.2837 - acc: 0.0000e+00 - val_loss: 0.2238 - val_acc: 0.0000e+00\n",
      "Epoch 131/300\n",
      "80/80 [==============================] - 0s 312us/step - loss: 0.2825 - acc: 0.0000e+00 - val_loss: 0.2241 - val_acc: 0.0000e+00\n",
      "Epoch 132/300\n",
      "80/80 [==============================] - 0s 324us/step - loss: 0.2812 - acc: 0.0000e+00 - val_loss: 0.2245 - val_acc: 0.0000e+00\n",
      "Epoch 133/300\n",
      "80/80 [==============================] - 0s 411us/step - loss: 0.2801 - acc: 0.0000e+00 - val_loss: 0.2248 - val_acc: 0.0000e+00\n",
      "Epoch 134/300\n",
      "80/80 [==============================] - 0s 511us/step - loss: 0.2786 - acc: 0.0000e+00 - val_loss: 0.2252 - val_acc: 0.0000e+00\n",
      "Epoch 135/300\n",
      "80/80 [==============================] - 0s 436us/step - loss: 0.2774 - acc: 0.0000e+00 - val_loss: 0.2255 - val_acc: 0.0000e+00\n",
      "Epoch 136/300\n",
      "80/80 [==============================] - 0s 424us/step - loss: 0.2764 - acc: 0.0000e+00 - val_loss: 0.2259 - val_acc: 0.0000e+00\n",
      "Epoch 137/300\n",
      "80/80 [==============================] - 0s 461us/step - loss: 0.2754 - acc: 0.0000e+00 - val_loss: 0.2262 - val_acc: 0.0000e+00\n",
      "Epoch 138/300\n",
      "80/80 [==============================] - 0s 474us/step - loss: 0.2742 - acc: 0.0000e+00 - val_loss: 0.2265 - val_acc: 0.0000e+00\n",
      "Epoch 139/300\n",
      "80/80 [==============================] - 0s 337us/step - loss: 0.2732 - acc: 0.0000e+00 - val_loss: 0.2268 - val_acc: 0.0000e+00\n",
      "Epoch 140/300\n",
      "80/80 [==============================] - 0s 324us/step - loss: 0.2725 - acc: 0.0000e+00 - val_loss: 0.2271 - val_acc: 0.0000e+00\n",
      "Epoch 141/300\n",
      "80/80 [==============================] - 0s 287us/step - loss: 0.2715 - acc: 0.0000e+00 - val_loss: 0.2275 - val_acc: 0.0000e+00\n",
      "Epoch 142/300\n",
      "80/80 [==============================] - 0s 312us/step - loss: 0.2707 - acc: 0.0000e+00 - val_loss: 0.2280 - val_acc: 0.0000e+00\n",
      "Epoch 143/300\n",
      "80/80 [==============================] - 0s 287us/step - loss: 0.2697 - acc: 0.0000e+00 - val_loss: 0.2285 - val_acc: 0.0000e+00\n",
      "Epoch 144/300\n",
      "80/80 [==============================] - 0s 287us/step - loss: 0.2690 - acc: 0.0000e+00 - val_loss: 0.2291 - val_acc: 0.0000e+00\n",
      "Epoch 145/300\n",
      "80/80 [==============================] - 0s 274us/step - loss: 0.2682 - acc: 0.0000e+00 - val_loss: 0.2296 - val_acc: 0.0000e+00\n",
      "Epoch 146/300\n",
      "80/80 [==============================] - 0s 299us/step - loss: 0.2675 - acc: 0.0000e+00 - val_loss: 0.2301 - val_acc: 0.0000e+00\n",
      "Epoch 147/300\n",
      "80/80 [==============================] - 0s 287us/step - loss: 0.2667 - acc: 0.0000e+00 - val_loss: 0.2306 - val_acc: 0.0000e+00\n",
      "Epoch 148/300\n",
      "80/80 [==============================] - 0s 299us/step - loss: 0.2660 - acc: 0.0000e+00 - val_loss: 0.2313 - val_acc: 0.0000e+00\n",
      "Epoch 149/300\n",
      "80/80 [==============================] - 0s 312us/step - loss: 0.2653 - acc: 0.0000e+00 - val_loss: 0.2320 - val_acc: 0.0000e+00\n",
      "Epoch 150/300\n",
      "80/80 [==============================] - 0s 299us/step - loss: 0.2647 - acc: 0.0000e+00 - val_loss: 0.2329 - val_acc: 0.0000e+00\n",
      "Epoch 151/300\n",
      "80/80 [==============================] - 0s 374us/step - loss: 0.2639 - acc: 0.0000e+00 - val_loss: 0.2337 - val_acc: 0.0000e+00\n",
      "Epoch 152/300\n",
      "80/80 [==============================] - 0s 424us/step - loss: 0.2632 - acc: 0.0000e+00 - val_loss: 0.2346 - val_acc: 0.0000e+00\n",
      "Epoch 153/300\n",
      "80/80 [==============================] - 0s 411us/step - loss: 0.2626 - acc: 0.0000e+00 - val_loss: 0.2354 - val_acc: 0.0000e+00\n",
      "Epoch 154/300\n",
      "80/80 [==============================] - 0s 349us/step - loss: 0.2619 - acc: 0.0000e+00 - val_loss: 0.2361 - val_acc: 0.0000e+00\n",
      "Epoch 155/300\n",
      "80/80 [==============================] - 0s 312us/step - loss: 0.2613 - acc: 0.0000e+00 - val_loss: 0.2368 - val_acc: 0.0000e+00\n",
      "Epoch 156/300\n",
      "80/80 [==============================] - 0s 312us/step - loss: 0.2609 - acc: 0.0000e+00 - val_loss: 0.2375 - val_acc: 0.0000e+00\n",
      "Epoch 157/300\n",
      "80/80 [==============================] - 0s 312us/step - loss: 0.2603 - acc: 0.0000e+00 - val_loss: 0.2381 - val_acc: 0.0000e+00\n",
      "Epoch 158/300\n",
      "80/80 [==============================] - 0s 312us/step - loss: 0.2598 - acc: 0.0000e+00 - val_loss: 0.2387 - val_acc: 0.0500\n",
      "Epoch 159/300\n",
      "80/80 [==============================] - 0s 312us/step - loss: 0.2594 - acc: 0.0000e+00 - val_loss: 0.2392 - val_acc: 0.0500\n",
      "Epoch 160/300\n",
      "80/80 [==============================] - 0s 299us/step - loss: 0.2589 - acc: 0.0000e+00 - val_loss: 0.2398 - val_acc: 0.0500\n",
      "Epoch 161/300\n",
      "80/80 [==============================] - 0s 299us/step - loss: 0.2586 - acc: 0.0000e+00 - val_loss: 0.2403 - val_acc: 0.0500\n",
      "Epoch 162/300\n",
      "80/80 [==============================] - 0s 337us/step - loss: 0.2582 - acc: 0.0000e+00 - val_loss: 0.2409 - val_acc: 0.0500\n",
      "Epoch 163/300\n",
      "80/80 [==============================] - 0s 349us/step - loss: 0.2578 - acc: 0.0000e+00 - val_loss: 0.2414 - val_acc: 0.0500\n",
      "Epoch 164/300\n",
      "80/80 [==============================] - 0s 312us/step - loss: 0.2574 - acc: 0.0000e+00 - val_loss: 0.2419 - val_acc: 0.0500\n",
      "Epoch 165/300\n",
      "80/80 [==============================] - 0s 299us/step - loss: 0.2573 - acc: 0.0000e+00 - val_loss: 0.2427 - val_acc: 0.0500\n",
      "Epoch 166/300\n",
      "80/80 [==============================] - 0s 337us/step - loss: 0.2568 - acc: 0.0000e+00 - val_loss: 0.2433 - val_acc: 0.0500\n",
      "Epoch 167/300\n",
      "80/80 [==============================] - 0s 299us/step - loss: 0.2564 - acc: 0.0000e+00 - val_loss: 0.2439 - val_acc: 0.0500\n",
      "Epoch 168/300\n",
      "80/80 [==============================] - 0s 337us/step - loss: 0.2560 - acc: 0.0000e+00 - val_loss: 0.2444 - val_acc: 0.0500\n",
      "Epoch 169/300\n",
      "80/80 [==============================] - 0s 337us/step - loss: 0.2559 - acc: 0.0000e+00 - val_loss: 0.2452 - val_acc: 0.0500\n",
      "Epoch 170/300\n",
      "80/80 [==============================] - 0s 299us/step - loss: 0.2555 - acc: 0.0000e+00 - val_loss: 0.2459 - val_acc: 0.0500\n",
      "Epoch 171/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80/80 [==============================] - 0s 312us/step - loss: 0.2551 - acc: 0.0000e+00 - val_loss: 0.2465 - val_acc: 0.0500\n",
      "Epoch 172/300\n",
      "80/80 [==============================] - 0s 287us/step - loss: 0.2549 - acc: 0.0000e+00 - val_loss: 0.2472 - val_acc: 0.0500\n",
      "Epoch 173/300\n",
      "80/80 [==============================] - 0s 287us/step - loss: 0.2547 - acc: 0.0000e+00 - val_loss: 0.2479 - val_acc: 0.0500\n",
      "Epoch 174/300\n",
      "80/80 [==============================] - 0s 299us/step - loss: 0.2543 - acc: 0.0000e+00 - val_loss: 0.2486 - val_acc: 0.0500\n",
      "Epoch 175/300\n",
      "80/80 [==============================] - 0s 287us/step - loss: 0.2540 - acc: 0.0000e+00 - val_loss: 0.2492 - val_acc: 0.0500\n",
      "Epoch 176/300\n",
      "80/80 [==============================] - 0s 274us/step - loss: 0.2537 - acc: 0.0000e+00 - val_loss: 0.2499 - val_acc: 0.0500\n",
      "Epoch 177/300\n",
      "80/80 [==============================] - 0s 299us/step - loss: 0.2535 - acc: 0.0000e+00 - val_loss: 0.2506 - val_acc: 0.0500\n",
      "Epoch 178/300\n",
      "80/80 [==============================] - 0s 287us/step - loss: 0.2533 - acc: 0.0000e+00 - val_loss: 0.2513 - val_acc: 0.0500\n",
      "Epoch 179/300\n",
      "80/80 [==============================] - 0s 312us/step - loss: 0.2531 - acc: 0.0000e+00 - val_loss: 0.2519 - val_acc: 0.0500\n",
      "Epoch 180/300\n",
      "80/80 [==============================] - 0s 324us/step - loss: 0.2528 - acc: 0.0000e+00 - val_loss: 0.2525 - val_acc: 0.0500\n",
      "Epoch 181/300\n",
      "80/80 [==============================] - 0s 362us/step - loss: 0.2527 - acc: 0.0000e+00 - val_loss: 0.2530 - val_acc: 0.0500\n",
      "Epoch 182/300\n",
      "80/80 [==============================] - 0s 324us/step - loss: 0.2524 - acc: 0.0000e+00 - val_loss: 0.2534 - val_acc: 0.0500\n",
      "Epoch 183/300\n",
      "80/80 [==============================] - 0s 337us/step - loss: 0.2523 - acc: 0.0000e+00 - val_loss: 0.2539 - val_acc: 0.0500\n",
      "Epoch 184/300\n",
      "80/80 [==============================] - 0s 399us/step - loss: 0.2522 - acc: 0.0000e+00 - val_loss: 0.2543 - val_acc: 0.0500\n",
      "Epoch 185/300\n",
      "80/80 [==============================] - 0s 436us/step - loss: 0.2520 - acc: 0.0000e+00 - val_loss: 0.2547 - val_acc: 0.0500\n",
      "Epoch 186/300\n",
      "80/80 [==============================] - 0s 312us/step - loss: 0.2519 - acc: 0.0000e+00 - val_loss: 0.2551 - val_acc: 0.0500\n",
      "Epoch 187/300\n",
      "80/80 [==============================] - 0s 287us/step - loss: 0.2518 - acc: 0.0000e+00 - val_loss: 0.2553 - val_acc: 0.0500\n",
      "Epoch 188/300\n",
      "80/80 [==============================] - 0s 312us/step - loss: 0.2516 - acc: 0.0000e+00 - val_loss: 0.2556 - val_acc: 0.0500\n",
      "Epoch 189/300\n",
      "80/80 [==============================] - ETA: 0s - loss: 0.2659 - acc: 0.0000e+0 - 0s 274us/step - loss: 0.2516 - acc: 0.0000e+00 - val_loss: 0.2561 - val_acc: 0.0500\n",
      "Epoch 190/300\n",
      "80/80 [==============================] - 0s 287us/step - loss: 0.2514 - acc: 0.0000e+00 - val_loss: 0.2565 - val_acc: 0.0500\n",
      "Epoch 191/300\n",
      "80/80 [==============================] - 0s 287us/step - loss: 0.2513 - acc: 0.0000e+00 - val_loss: 0.2570 - val_acc: 0.0500\n",
      "Epoch 192/300\n",
      "80/80 [==============================] - 0s 299us/step - loss: 0.2512 - acc: 0.0000e+00 - val_loss: 0.2574 - val_acc: 0.0500\n",
      "Epoch 193/300\n",
      "80/80 [==============================] - 0s 274us/step - loss: 0.2511 - acc: 0.0000e+00 - val_loss: 0.2578 - val_acc: 0.0500\n",
      "Epoch 194/300\n",
      "80/80 [==============================] - 0s 287us/step - loss: 0.2510 - acc: 0.0000e+00 - val_loss: 0.2580 - val_acc: 0.0500\n",
      "Epoch 195/300\n",
      "80/80 [==============================] - 0s 299us/step - loss: 0.2509 - acc: 0.0000e+00 - val_loss: 0.2583 - val_acc: 0.0500\n",
      "Epoch 196/300\n",
      "80/80 [==============================] - 0s 299us/step - loss: 0.2508 - acc: 0.0000e+00 - val_loss: 0.2586 - val_acc: 0.0500\n",
      "Epoch 197/300\n",
      "80/80 [==============================] - 0s 287us/step - loss: 0.2507 - acc: 0.0000e+00 - val_loss: 0.2589 - val_acc: 0.0500\n",
      "Epoch 198/300\n",
      "80/80 [==============================] - 0s 287us/step - loss: 0.2506 - acc: 0.0000e+00 - val_loss: 0.2591 - val_acc: 0.0500\n",
      "Epoch 199/300\n",
      "80/80 [==============================] - 0s 274us/step - loss: 0.2505 - acc: 0.0000e+00 - val_loss: 0.2594 - val_acc: 0.0500\n",
      "Epoch 200/300\n",
      "80/80 [==============================] - 0s 299us/step - loss: 0.2505 - acc: 0.0000e+00 - val_loss: 0.2597 - val_acc: 0.0500\n",
      "Epoch 201/300\n",
      "80/80 [==============================] - 0s 299us/step - loss: 0.2504 - acc: 0.0000e+00 - val_loss: 0.2600 - val_acc: 0.0500\n",
      "Epoch 202/300\n",
      "80/80 [==============================] - 0s 299us/step - loss: 0.2504 - acc: 0.0000e+00 - val_loss: 0.2602 - val_acc: 0.0500\n",
      "Epoch 203/300\n",
      "80/80 [==============================] - 0s 299us/step - loss: 0.2503 - acc: 0.0000e+00 - val_loss: 0.2603 - val_acc: 0.0500\n",
      "Epoch 204/300\n",
      "80/80 [==============================] - 0s 287us/step - loss: 0.2502 - acc: 0.0000e+00 - val_loss: 0.2603 - val_acc: 0.0500\n",
      "Epoch 205/300\n",
      "80/80 [==============================] - 0s 287us/step - loss: 0.2502 - acc: 0.0000e+00 - val_loss: 0.2604 - val_acc: 0.0500\n",
      "Epoch 206/300\n",
      "80/80 [==============================] - 0s 324us/step - loss: 0.2501 - acc: 0.0000e+00 - val_loss: 0.2603 - val_acc: 0.0500\n",
      "Epoch 207/300\n",
      "80/80 [==============================] - 0s 287us/step - loss: 0.2501 - acc: 0.0000e+00 - val_loss: 0.2601 - val_acc: 0.0500\n",
      "Epoch 208/300\n",
      "80/80 [==============================] - 0s 324us/step - loss: 0.2500 - acc: 0.0000e+00 - val_loss: 0.2602 - val_acc: 0.0500\n",
      "Epoch 209/300\n",
      "80/80 [==============================] - 0s 324us/step - loss: 0.2500 - acc: 0.0000e+00 - val_loss: 0.2600 - val_acc: 0.0500\n",
      "Epoch 210/300\n",
      "80/80 [==============================] - 0s 287us/step - loss: 0.2499 - acc: 0.0000e+00 - val_loss: 0.2601 - val_acc: 0.0500\n",
      "Epoch 211/300\n",
      "80/80 [==============================] - 0s 312us/step - loss: 0.2499 - acc: 0.0000e+00 - val_loss: 0.2600 - val_acc: 0.0500\n",
      "Epoch 212/300\n",
      "80/80 [==============================] - 0s 324us/step - loss: 0.2498 - acc: 0.0000e+00 - val_loss: 0.2599 - val_acc: 0.0500\n",
      "Epoch 213/300\n",
      "80/80 [==============================] - 0s 299us/step - loss: 0.2498 - acc: 0.0000e+00 - val_loss: 0.2597 - val_acc: 0.0500\n",
      "Epoch 214/300\n",
      "80/80 [==============================] - 0s 274us/step - loss: 0.2498 - acc: 0.0000e+00 - val_loss: 0.2596 - val_acc: 0.0500\n",
      "Epoch 215/300\n",
      "80/80 [==============================] - 0s 449us/step - loss: 0.2497 - acc: 0.0000e+00 - val_loss: 0.2595 - val_acc: 0.0500\n",
      "Epoch 216/300\n",
      "80/80 [==============================] - 0s 312us/step - loss: 0.2497 - acc: 0.0000e+00 - val_loss: 0.2595 - val_acc: 0.0500\n",
      "Epoch 217/300\n",
      "80/80 [==============================] - 0s 324us/step - loss: 0.2497 - acc: 0.0000e+00 - val_loss: 0.2596 - val_acc: 0.0500\n",
      "Epoch 218/300\n",
      "80/80 [==============================] - 0s 324us/step - loss: 0.2497 - acc: 0.0000e+00 - val_loss: 0.2597 - val_acc: 0.0500\n",
      "Epoch 219/300\n",
      "80/80 [==============================] - 0s 411us/step - loss: 0.2496 - acc: 0.0000e+00 - val_loss: 0.2597 - val_acc: 0.0500\n",
      "Epoch 220/300\n",
      "80/80 [==============================] - 0s 386us/step - loss: 0.2496 - acc: 0.0000e+00 - val_loss: 0.2598 - val_acc: 0.0500\n",
      "Epoch 221/300\n",
      "80/80 [==============================] - 0s 611us/step - loss: 0.2495 - acc: 0.0000e+00 - val_loss: 0.2599 - val_acc: 0.0500\n",
      "Epoch 222/300\n",
      "80/80 [==============================] - 0s 424us/step - loss: 0.2495 - acc: 0.0000e+00 - val_loss: 0.2599 - val_acc: 0.0500\n",
      "Epoch 223/300\n",
      "80/80 [==============================] - 0s 399us/step - loss: 0.2494 - acc: 0.0000e+00 - val_loss: 0.2599 - val_acc: 0.0500\n",
      "Epoch 224/300\n",
      "80/80 [==============================] - 0s 312us/step - loss: 0.2494 - acc: 0.0000e+00 - val_loss: 0.2598 - val_acc: 0.0500\n",
      "Epoch 225/300\n",
      "80/80 [==============================] - 0s 287us/step - loss: 0.2494 - acc: 0.0000e+00 - val_loss: 0.2597 - val_acc: 0.0500\n",
      "Epoch 226/300\n",
      "80/80 [==============================] - 0s 299us/step - loss: 0.2494 - acc: 0.0000e+00 - val_loss: 0.2598 - val_acc: 0.0500\n",
      "Epoch 227/300\n",
      "80/80 [==============================] - 0s 274us/step - loss: 0.2493 - acc: 0.0000e+00 - val_loss: 0.2598 - val_acc: 0.0500\n",
      "Epoch 228/300\n",
      "80/80 [==============================] - 0s 299us/step - loss: 0.2493 - acc: 0.0000e+00 - val_loss: 0.2599 - val_acc: 0.0500\n",
      "Epoch 229/300\n",
      "80/80 [==============================] - 0s 287us/step - loss: 0.2493 - acc: 0.0000e+00 - val_loss: 0.2600 - val_acc: 0.0500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 230/300\n",
      "80/80 [==============================] - 0s 287us/step - loss: 0.2492 - acc: 0.0000e+00 - val_loss: 0.2601 - val_acc: 0.0500\n",
      "Epoch 231/300\n",
      "80/80 [==============================] - 0s 299us/step - loss: 0.2492 - acc: 0.0000e+00 - val_loss: 0.2600 - val_acc: 0.0500\n",
      "Epoch 232/300\n",
      "80/80 [==============================] - 0s 274us/step - loss: 0.2492 - acc: 0.0000e+00 - val_loss: 0.2599 - val_acc: 0.0500\n",
      "Epoch 233/300\n",
      "80/80 [==============================] - 0s 274us/step - loss: 0.2491 - acc: 0.0000e+00 - val_loss: 0.2599 - val_acc: 0.0500\n",
      "Epoch 234/300\n",
      "80/80 [==============================] - 0s 349us/step - loss: 0.2491 - acc: 0.0000e+00 - val_loss: 0.2599 - val_acc: 0.0500\n",
      "Epoch 235/300\n",
      "80/80 [==============================] - 0s 287us/step - loss: 0.2491 - acc: 0.0000e+00 - val_loss: 0.2599 - val_acc: 0.0500\n",
      "Epoch 236/300\n",
      "80/80 [==============================] - 0s 337us/step - loss: 0.2491 - acc: 0.0000e+00 - val_loss: 0.2598 - val_acc: 0.0500\n",
      "Epoch 237/300\n",
      "80/80 [==============================] - 0s 274us/step - loss: 0.2490 - acc: 0.0000e+00 - val_loss: 0.2599 - val_acc: 0.0500\n",
      "Epoch 238/300\n",
      "80/80 [==============================] - 0s 274us/step - loss: 0.2490 - acc: 0.0000e+00 - val_loss: 0.2599 - val_acc: 0.0500\n",
      "Epoch 239/300\n",
      "80/80 [==============================] - 0s 274us/step - loss: 0.2490 - acc: 0.0000e+00 - val_loss: 0.2598 - val_acc: 0.0500\n",
      "Epoch 240/300\n",
      "80/80 [==============================] - 0s 312us/step - loss: 0.2490 - acc: 0.0000e+00 - val_loss: 0.2597 - val_acc: 0.0500\n",
      "Epoch 241/300\n",
      "80/80 [==============================] - 0s 324us/step - loss: 0.2489 - acc: 0.0000e+00 - val_loss: 0.2598 - val_acc: 0.0500\n",
      "Epoch 242/300\n",
      "80/80 [==============================] - 0s 299us/step - loss: 0.2489 - acc: 0.0000e+00 - val_loss: 0.2599 - val_acc: 0.0500\n",
      "Epoch 243/300\n",
      "80/80 [==============================] - 0s 299us/step - loss: 0.2489 - acc: 0.0000e+00 - val_loss: 0.2601 - val_acc: 0.0500\n",
      "Epoch 244/300\n",
      "80/80 [==============================] - 0s 287us/step - loss: 0.2488 - acc: 0.0000e+00 - val_loss: 0.2601 - val_acc: 0.0500\n",
      "Epoch 245/300\n",
      "80/80 [==============================] - 0s 287us/step - loss: 0.2488 - acc: 0.0000e+00 - val_loss: 0.2602 - val_acc: 0.0500\n",
      "Epoch 246/300\n",
      "80/80 [==============================] - 0s 274us/step - loss: 0.2488 - acc: 0.0000e+00 - val_loss: 0.2601 - val_acc: 0.0500\n",
      "Epoch 247/300\n",
      "80/80 [==============================] - 0s 299us/step - loss: 0.2488 - acc: 0.0000e+00 - val_loss: 0.2602 - val_acc: 0.0500\n",
      "Epoch 248/300\n",
      "80/80 [==============================] - 0s 299us/step - loss: 0.2488 - acc: 0.0000e+00 - val_loss: 0.2605 - val_acc: 0.0500\n",
      "Epoch 249/300\n",
      "80/80 [==============================] - 0s 299us/step - loss: 0.2487 - acc: 0.0000e+00 - val_loss: 0.2606 - val_acc: 0.0500\n",
      "Epoch 250/300\n",
      "80/80 [==============================] - 0s 312us/step - loss: 0.2487 - acc: 0.0000e+00 - val_loss: 0.2606 - val_acc: 0.0500\n",
      "Epoch 251/300\n",
      "80/80 [==============================] - 0s 274us/step - loss: 0.2487 - acc: 0.0000e+00 - val_loss: 0.2605 - val_acc: 0.0500\n",
      "Epoch 252/300\n",
      "80/80 [==============================] - 0s 299us/step - loss: 0.2486 - acc: 0.0000e+00 - val_loss: 0.2605 - val_acc: 0.0500\n",
      "Epoch 253/300\n",
      "80/80 [==============================] - 0s 287us/step - loss: 0.2486 - acc: 0.0000e+00 - val_loss: 0.2605 - val_acc: 0.0500\n",
      "Epoch 254/300\n",
      "80/80 [==============================] - 0s 299us/step - loss: 0.2486 - acc: 0.0000e+00 - val_loss: 0.2606 - val_acc: 0.0500\n",
      "Epoch 255/300\n",
      "80/80 [==============================] - 0s 312us/step - loss: 0.2486 - acc: 0.0000e+00 - val_loss: 0.2608 - val_acc: 0.0500\n",
      "Epoch 256/300\n",
      "80/80 [==============================] - 0s 274us/step - loss: 0.2485 - acc: 0.0000e+00 - val_loss: 0.2609 - val_acc: 0.0500\n",
      "Epoch 257/300\n",
      "80/80 [==============================] - 0s 312us/step - loss: 0.2485 - acc: 0.0000e+00 - val_loss: 0.2612 - val_acc: 0.0500\n",
      "Epoch 258/300\n",
      "80/80 [==============================] - 0s 287us/step - loss: 0.2485 - acc: 0.0000e+00 - val_loss: 0.2615 - val_acc: 0.0500\n",
      "Epoch 259/300\n",
      "80/80 [==============================] - 0s 299us/step - loss: 0.2485 - acc: 0.0000e+00 - val_loss: 0.2617 - val_acc: 0.0500\n",
      "Epoch 260/300\n",
      "80/80 [==============================] - 0s 274us/step - loss: 0.2484 - acc: 0.0000e+00 - val_loss: 0.2617 - val_acc: 0.0500\n",
      "Epoch 261/300\n",
      "80/80 [==============================] - 0s 299us/step - loss: 0.2484 - acc: 0.0000e+00 - val_loss: 0.2617 - val_acc: 0.0500\n",
      "Epoch 262/300\n",
      "80/80 [==============================] - 0s 287us/step - loss: 0.2484 - acc: 0.0000e+00 - val_loss: 0.2618 - val_acc: 0.0500\n",
      "Epoch 263/300\n",
      "80/80 [==============================] - 0s 299us/step - loss: 0.2483 - acc: 0.0000e+00 - val_loss: 0.2618 - val_acc: 0.0500\n",
      "Epoch 264/300\n",
      "80/80 [==============================] - 0s 287us/step - loss: 0.2483 - acc: 0.0000e+00 - val_loss: 0.2619 - val_acc: 0.0500\n",
      "Epoch 265/300\n",
      "80/80 [==============================] - 0s 299us/step - loss: 0.2483 - acc: 0.0000e+00 - val_loss: 0.2619 - val_acc: 0.0500\n",
      "Epoch 266/300\n",
      "80/80 [==============================] - 0s 299us/step - loss: 0.2483 - acc: 0.0000e+00 - val_loss: 0.2619 - val_acc: 0.0500\n",
      "Epoch 267/300\n",
      "80/80 [==============================] - 0s 287us/step - loss: 0.2483 - acc: 0.0000e+00 - val_loss: 0.2619 - val_acc: 0.0500\n",
      "Epoch 268/300\n",
      "80/80 [==============================] - 0s 299us/step - loss: 0.2482 - acc: 0.0000e+00 - val_loss: 0.2619 - val_acc: 0.0500\n",
      "Epoch 269/300\n",
      "80/80 [==============================] - 0s 287us/step - loss: 0.2482 - acc: 0.0000e+00 - val_loss: 0.2620 - val_acc: 0.0500\n",
      "Epoch 270/300\n",
      "80/80 [==============================] - 0s 287us/step - loss: 0.2482 - acc: 0.0000e+00 - val_loss: 0.2621 - val_acc: 0.0500\n",
      "Epoch 271/300\n",
      "80/80 [==============================] - 0s 287us/step - loss: 0.2481 - acc: 0.0000e+00 - val_loss: 0.2621 - val_acc: 0.0500\n",
      "Epoch 272/300\n",
      "80/80 [==============================] - 0s 287us/step - loss: 0.2481 - acc: 0.0000e+00 - val_loss: 0.2621 - val_acc: 0.0500\n",
      "Epoch 273/300\n",
      "80/80 [==============================] - 0s 299us/step - loss: 0.2481 - acc: 0.0000e+00 - val_loss: 0.2622 - val_acc: 0.0500\n",
      "Epoch 274/300\n",
      "80/80 [==============================] - 0s 274us/step - loss: 0.2481 - acc: 0.0000e+00 - val_loss: 0.2623 - val_acc: 0.0500\n",
      "Epoch 275/300\n",
      "80/80 [==============================] - 0s 312us/step - loss: 0.2480 - acc: 0.0000e+00 - val_loss: 0.2625 - val_acc: 0.0500\n",
      "Epoch 276/300\n",
      "80/80 [==============================] - 0s 274us/step - loss: 0.2480 - acc: 0.0000e+00 - val_loss: 0.2627 - val_acc: 0.0500\n",
      "Epoch 277/300\n",
      "80/80 [==============================] - 0s 287us/step - loss: 0.2480 - acc: 0.0000e+00 - val_loss: 0.2629 - val_acc: 0.0500\n",
      "Epoch 278/300\n",
      "80/80 [==============================] - 0s 386us/step - loss: 0.2480 - acc: 0.0000e+00 - val_loss: 0.2631 - val_acc: 0.0500\n",
      "Epoch 279/300\n",
      "80/80 [==============================] - 0s 324us/step - loss: 0.2479 - acc: 0.0000e+00 - val_loss: 0.2632 - val_acc: 0.0500\n",
      "Epoch 280/300\n",
      "80/80 [==============================] - 0s 299us/step - loss: 0.2479 - acc: 0.0000e+00 - val_loss: 0.2631 - val_acc: 0.0500\n",
      "Epoch 281/300\n",
      "80/80 [==============================] - 0s 274us/step - loss: 0.2479 - acc: 0.0000e+00 - val_loss: 0.2630 - val_acc: 0.0500\n",
      "Epoch 282/300\n",
      "80/80 [==============================] - 0s 274us/step - loss: 0.2479 - acc: 0.0000e+00 - val_loss: 0.2632 - val_acc: 0.0500\n",
      "Epoch 283/300\n",
      "80/80 [==============================] - 0s 299us/step - loss: 0.2478 - acc: 0.0000e+00 - val_loss: 0.2631 - val_acc: 0.0500\n",
      "Epoch 284/300\n",
      "80/80 [==============================] - 0s 287us/step - loss: 0.2478 - acc: 0.0000e+00 - val_loss: 0.2631 - val_acc: 0.0500\n",
      "Epoch 285/300\n",
      "80/80 [==============================] - 0s 287us/step - loss: 0.2478 - acc: 0.0000e+00 - val_loss: 0.2632 - val_acc: 0.0500\n",
      "Epoch 286/300\n",
      "80/80 [==============================] - 0s 324us/step - loss: 0.2478 - acc: 0.0000e+00 - val_loss: 0.2634 - val_acc: 0.0500\n",
      "Epoch 287/300\n",
      "80/80 [==============================] - 0s 312us/step - loss: 0.2477 - acc: 0.0000e+00 - val_loss: 0.2634 - val_acc: 0.0500\n",
      "Epoch 288/300\n",
      "80/80 [==============================] - 0s 299us/step - loss: 0.2477 - acc: 0.0000e+00 - val_loss: 0.2634 - val_acc: 0.0500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 289/300\n",
      "80/80 [==============================] - 0s 312us/step - loss: 0.2476 - acc: 0.0000e+00 - val_loss: 0.2635 - val_acc: 0.0500\n",
      "Epoch 290/300\n",
      "80/80 [==============================] - 0s 287us/step - loss: 0.2476 - acc: 0.0000e+00 - val_loss: 0.2636 - val_acc: 0.0500\n",
      "Epoch 291/300\n",
      "80/80 [==============================] - 0s 312us/step - loss: 0.2476 - acc: 0.0000e+00 - val_loss: 0.2637 - val_acc: 0.0500\n",
      "Epoch 292/300\n",
      "80/80 [==============================] - 0s 287us/step - loss: 0.2476 - acc: 0.0000e+00 - val_loss: 0.2636 - val_acc: 0.0500\n",
      "Epoch 293/300\n",
      "80/80 [==============================] - 0s 299us/step - loss: 0.2475 - acc: 0.0000e+00 - val_loss: 0.2634 - val_acc: 0.0500\n",
      "Epoch 294/300\n",
      "80/80 [==============================] - 0s 274us/step - loss: 0.2475 - acc: 0.0000e+00 - val_loss: 0.2633 - val_acc: 0.0500\n",
      "Epoch 295/300\n",
      "80/80 [==============================] - 0s 287us/step - loss: 0.2475 - acc: 0.0000e+00 - val_loss: 0.2636 - val_acc: 0.0500\n",
      "Epoch 296/300\n",
      "80/80 [==============================] - 0s 287us/step - loss: 0.2474 - acc: 0.0000e+00 - val_loss: 0.2636 - val_acc: 0.0500\n",
      "Epoch 297/300\n",
      "80/80 [==============================] - 0s 299us/step - loss: 0.2474 - acc: 0.0000e+00 - val_loss: 0.2638 - val_acc: 0.0500\n",
      "Epoch 298/300\n",
      "80/80 [==============================] - 0s 312us/step - loss: 0.2474 - acc: 0.0000e+00 - val_loss: 0.2639 - val_acc: 0.0500\n",
      "Epoch 299/300\n",
      "80/80 [==============================] - 0s 299us/step - loss: 0.2473 - acc: 0.0000e+00 - val_loss: 0.2639 - val_acc: 0.0500\n",
      "Epoch 300/300\n",
      "80/80 [==============================] - 0s 386us/step - loss: 0.2473 - acc: 0.0000e+00 - val_loss: 0.2640 - val_acc: 0.0500\n"
     ]
    }
   ],
   "source": [
    "history=model.fit(x_train,y_train,epochs=300,validation_data=(x_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "results=model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(range(20),results,c='r')\n",
    "plt.scatter(range(20),y_test,c='g')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
