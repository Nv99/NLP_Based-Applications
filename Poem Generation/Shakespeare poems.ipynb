{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from keras.callbacks import LambdaCallback\n",
    "from keras.models import Model, load_model, Sequential\n",
    "from keras.layers import Dense, Activation, Dropout, Input, Masking\n",
    "from keras.layers import LSTM\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "import sys\n",
    "import io\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading text data...\n",
      "Creating training set...\n",
      "number of training examples: 31412\n",
      "Vectorizing training set...\n",
      "Loading model...\n",
      "WARNING:tensorflow:From C:\\Users\\lenovo\\AppData\\Local\\conda\\conda\\envs\\tensorflow\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\lenovo\\AppData\\Local\\conda\\conda\\envs\\tensorflow\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\lenovo\\AppData\\Local\\conda\\conda\\envs\\tensorflow\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\lenovo\\AppData\\Local\\conda\\conda\\envs\\tensorflow\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\lenovo\\AppData\\Local\\conda\\conda\\envs\\tensorflow\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From C:\\Users\\lenovo\\AppData\\Local\\conda\\conda\\envs\\tensorflow\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\lenovo\\AppData\\Local\\conda\\conda\\envs\\tensorflow\\lib\\site-packages\\keras\\optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\lenovo\\AppData\\Local\\conda\\conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lenovo\\AppData\\Local\\conda\\conda\\envs\\tensorflow\\lib\\site-packages\\keras\\engine\\saving.py:327: UserWarning: Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n",
      "  warnings.warn('Error in loading the saved optimizer '\n"
     ]
    }
   ],
   "source": [
    "def build_data(text, Tx = 40, stride = 3):\n",
    "    \"\"\"\n",
    "    Create a training set by scanning a window of size Tx over the text corpus, with stride 3.\n",
    "    \n",
    "    Arguments:\n",
    "    text -- string, corpus of Shakespearian poem\n",
    "    Tx -- sequence length, number of time-steps (or characters) in one training example\n",
    "    stride -- how much the window shifts itself while scanning\n",
    "    \n",
    "    Returns:\n",
    "    X -- list of training examples\n",
    "    Y -- list of training labels\n",
    "    \"\"\"\n",
    "    \n",
    "    X = []\n",
    "    Y = []\n",
    "\n",
    "    ### START CODE HERE ### (â‰ˆ 3 lines)\n",
    "    for i in range(0, len(text) - Tx, stride):\n",
    "        X.append(text[i: i + Tx])\n",
    "        Y.append(text[i + Tx])\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    print('number of training examples:', len(X))\n",
    "    \n",
    "    return X, Y\n",
    "\n",
    "\n",
    "def vectorization(X, Y, n_x, char_indices, Tx = 40):\n",
    "    \"\"\"\n",
    "    Convert X and Y (lists) into arrays to be given to a recurrent neural network.\n",
    "    \n",
    "    Arguments:\n",
    "    X -- \n",
    "    Y -- \n",
    "    Tx -- integer, sequence length\n",
    "    \n",
    "    Returns:\n",
    "    x -- array of shape (m, Tx, len(chars))\n",
    "    y -- array of shape (m, len(chars))\n",
    "    \"\"\"\n",
    "    \n",
    "    m = len(X)\n",
    "    x = np.zeros((m, Tx, n_x), dtype=np.bool)\n",
    "    y = np.zeros((m, n_x), dtype=np.bool)\n",
    "    for i, sentence in enumerate(X):\n",
    "        for t, char in enumerate(sentence):\n",
    "            x[i, t, char_indices[char]] = 1\n",
    "        y[i, char_indices[Y[i]]] = 1\n",
    "        \n",
    "    return x, y \n",
    "\n",
    "\n",
    "def sample(preds, temperature=1.0):\n",
    "    # helper function to sample an index from a probability array\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds) / temperature\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    probas = np.random.multinomial(1, preds, 1)\n",
    "    out = np.random.choice(range(len(chars)), p = probas.ravel())\n",
    "    return out\n",
    "    #return np.argmax(probas)\n",
    "    \n",
    "def on_epoch_end(epoch, logs):\n",
    "    # Function invoked at end of each epoch. Prints generated text.\n",
    "    None\n",
    "    #start_index = random.randint(0, len(text) - Tx - 1)\n",
    "    \n",
    "    #generated = ''\n",
    "    #sentence = text[start_index: start_index + Tx]\n",
    "    #sentence = '0'*Tx\n",
    "    #usr_input = input(\"Write the beginning of your poem, the Shakespearian machine will complete it.\")\n",
    "    # zero pad the sentence to Tx characters.\n",
    "    #sentence = ('{0:0>' + str(Tx) + '}').format(usr_input).lower()\n",
    "    #generated += sentence\n",
    "#\n",
    "    #sys.stdout.write(usr_input)\n",
    "\n",
    "    #for i in range(400):\n",
    "\"\"\"\n",
    "        #x_pred = np.zeros((1, Tx, len(chars)))\n",
    "\n",
    "        for t, char in enumerate(sentence):\n",
    "            if char != '0':\n",
    "                x_pred[0, t, char_indices[char]] = 1.\n",
    "\n",
    "        preds = model.predict(x_pred, verbose=0)[0]\n",
    "        next_index = sample(preds, temperature = 1.0)\n",
    "        next_char = indices_char[next_index]\n",
    "\n",
    "        generated += next_char\n",
    "        sentence = sentence[1:] + next_char\n",
    "\n",
    "        sys.stdout.write(next_char)\n",
    "        sys.stdout.flush()\n",
    "        \n",
    "        if next_char == '\\n':\n",
    "            continue\n",
    "        \n",
    "    # Stop at the end of a line (4 lines)\n",
    "    print()\n",
    " \"\"\"   \n",
    "print(\"Loading text data...\")\n",
    "text = io.open('shakespeare.txt', encoding='utf-8').read().lower()\n",
    "#print('corpus length:', len(text))\n",
    "\n",
    "Tx = 40\n",
    "chars = sorted(list(set(text)))\n",
    "char_indices = dict((c, i) for i, c in enumerate(chars))\n",
    "indices_char = dict((i, c) for i, c in enumerate(chars))\n",
    "#print('number of unique characters in the corpus:', len(chars))\n",
    "\n",
    "print(\"Creating training set...\")\n",
    "X, Y = build_data(text, Tx, stride = 3)\n",
    "print(\"Vectorizing training set...\")\n",
    "x, y = vectorization(X, Y, n_x = len(chars), char_indices = char_indices) \n",
    "print(\"Loading model...\")\n",
    "model = load_model('models/model_shakespeare_kiank_350_epoch.h5')\n",
    "\n",
    "\n",
    "def generate_output():\n",
    "    generated = ''\n",
    "    #sentence = text[start_index: start_index + Tx]\n",
    "    #sentence = '0'*Tx\n",
    "    usr_input = input(\"Write the beginning of your poem, the Shakespeare machine will complete it. Your input is: \")\n",
    "    # zero pad the sentence to Tx characters.\n",
    "    sentence = ('{0:0>' + str(Tx) + '}').format(usr_input).lower()\n",
    "    generated += usr_input \n",
    "\n",
    "    sys.stdout.write(\"\\n\\nHere is your poem: \\n\\n\") \n",
    "    sys.stdout.write(usr_input)\n",
    "    for i in range(400):\n",
    "\n",
    "        x_pred = np.zeros((1, Tx, len(chars)))\n",
    "\n",
    "        for t, char in enumerate(sentence):\n",
    "            if char != '0':\n",
    "                x_pred[0, t, char_indices[char]] = 1.\n",
    "\n",
    "        preds = model.predict(x_pred, verbose=0)[0]\n",
    "        next_index = sample(preds, temperature = 1.0)\n",
    "        next_char = indices_char[next_index]\n",
    "\n",
    "        generated += next_char\n",
    "        sentence = sentence[1:] + next_char\n",
    "\n",
    "        sys.stdout.write(next_char)\n",
    "        sys.stdout.flush()\n",
    "\n",
    "        if next_char == '\\n':\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "31412/31412 [==============================] - 57s 2ms/step - loss: 2.7201\n",
      "Epoch 2/15\n",
      "31412/31412 [==============================] - 50s 2ms/step - loss: 2.0896\n",
      "Epoch 3/15\n",
      "31412/31412 [==============================] - 50s 2ms/step - loss: 1.9471\n",
      "Epoch 4/15\n",
      "31412/31412 [==============================] - 48s 2ms/step - loss: 1.8889\n",
      "Epoch 5/15\n",
      "31412/31412 [==============================] - 52s 2ms/step - loss: 1.8449\n",
      "Epoch 6/15\n",
      "31412/31412 [==============================] - 51s 2ms/step - loss: 1.8063\n",
      "Epoch 7/15\n",
      "31412/31412 [==============================] - 49s 2ms/step - loss: 1.7844\n",
      "Epoch 8/15\n",
      "31412/31412 [==============================] - 48s 2ms/step - loss: 1.7508\n",
      "Epoch 9/15\n",
      "31412/31412 [==============================] - 47s 2ms/step - loss: 1.7316\n",
      "Epoch 10/15\n",
      "31412/31412 [==============================] - 47s 1ms/step - loss: 1.7152: 1s - lo\n",
      "Epoch 11/15\n",
      "31412/31412 [==============================] - 48s 2ms/step - loss: 1.6930\n",
      "Epoch 12/15\n",
      "31412/31412 [==============================] - 52s 2ms/step - loss: 1.6645\n",
      "Epoch 13/15\n",
      "31412/31412 [==============================] - 49s 2ms/step - loss: 1.6517\n",
      "Epoch 14/15\n",
      "31412/31412 [==============================] - 48s 2ms/step - loss: 1.6289\n",
      "Epoch 15/15\n",
      "31412/31412 [==============================] - 49s 2ms/step - loss: 1.6141\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x19d60efb0f0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print_callback = LambdaCallback(on_epoch_end=on_epoch_end)\n",
    "\n",
    "model.fit(x, y, batch_size=128, epochs=15, callbacks=[print_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Write the beginning of your poem, the Shakespeare machine will complete it. Your input is: Leaves and stones\n",
      "\n",
      "\n",
      "Here is your poem: \n",
      "\n",
      "Leaves and stones,\n",
      "and eye of leaves might eveny of the clean.\n",
      "brast of yet of are as that ry dincdeesed.\n",
      "i thou i doth of thy grace of not mey\n",
      "phoven saale you wat, do dos no lels thou ,try not.\n",
      "\n",
      "\n",
      "\n",
      "an thou me thing thy shart lotiin, in my spile\n",
      "as my his tryat now fow thy some thou desher tices,\n",
      "and sal yeing to imgean do why sweet goved:\n",
      "beter ever sumeer that i jure this ady land.\n",
      "\n",
      "searned thiss with blan'st th"
     ]
    }
   ],
   "source": [
    "# Run this cell to try with different inputs without having to re-train the model \n",
    "generate_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
